{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQ8FRFIYMc5X"
      },
      "source": [
        "# HOMEWORK 6: TEXT CLASSIFICATION\n",
        "In this homework, you will create models to classify texts from TRUE call-center. There are two classification tasks:\n",
        "1. Action Classification: Identify which action the customer would like to take (e.g. enquire, report, cancle)\n",
        "2. Object Classification: Identify which object the customer is referring to (e.g. payment, truemoney, internet, roaming)\n",
        "\n",
        "We will focus only on the Object Classification task for this homework.\n",
        "\n",
        "In this homework, you are asked compare different text classification models in terms of accuracy and inference time.\n",
        "\n",
        "You will need to build 3 different models.\n",
        "\n",
        "1. A model based on tf-idf\n",
        "2. A model based on MUSE\n",
        "3. A model based on wangchanBERTa\n",
        "\n",
        "**You will be ask to submit 3 different files (.pdf from .ipynb) that does the 3 different models. Finally, answer the accuracy and runtime numbers in MCV.**\n",
        "\n",
        "This homework is quite free form, and your answer may vary. We hope that the processing during the course of this assignment will make you think more about the design choices in text classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kHqkFSyaNvOt",
        "outputId": "879b17f1-0fb2-455c-ca37-b5a4aecd7b1c"
      },
      "outputs": [],
      "source": [
        "# !wget --no-check-certificate https://www.dropbox.com/s/37u83g55p19kvrl/clean-phone-data-for-students.csv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qRlx5Mb5zkXw",
        "outputId": "18d913e0-aa6d-435b-931d-591386cb4ba8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pythainlp in /Users/pupipatsingkhorn/miniconda3/envs/datascience/lib/python3.11/site-packages (5.0.5)\n",
            "Requirement already satisfied: requests>=2.22.0 in /Users/pupipatsingkhorn/miniconda3/envs/datascience/lib/python3.11/site-packages (from pythainlp) (2.32.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pupipatsingkhorn/miniconda3/envs/datascience/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/pupipatsingkhorn/miniconda3/envs/datascience/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pupipatsingkhorn/miniconda3/envs/datascience/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/pupipatsingkhorn/miniconda3/envs/datascience/lib/python3.11/site-packages (from requests>=2.22.0->pythainlp) (2025.1.31)\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        }
      ],
      "source": [
        "%pip install pythainlp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2YprqbOPMc5a"
      },
      "source": [
        "## Import Libs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "heICP79cMc5e"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import pandas\n",
        "import sklearn\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "\n",
        "from torch.utils.data import Dataset\n",
        "from IPython.display import display\n",
        "from collections import defaultdict\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "SEED = 42"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GPaUf4PLMc5k"
      },
      "source": [
        "## Loading data\n",
        "First, we load the data from disk into a Dataframe.\n",
        "\n",
        "A Dataframe is essentially a table, or 2D-array/Matrix with a name for each column."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "JhZ2eBAWMc5l"
      },
      "outputs": [],
      "source": [
        "data_df = pd.read_csv('clean-phone-data-for-students.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cje3yruTMc5p"
      },
      "source": [
        "Let's preview the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 364
        },
        "id": "aNqRNz1PMc5q",
        "outputId": "e129a502-1420-476c-dc50-46c293a01b56"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counte...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>payment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>internet ยังความเร็วอยุ่เท่าไหร ครับ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>package</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...</td>\n",
              "      <td>report</td>\n",
              "      <td>suspend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...</td>\n",
              "      <td>enquire</td>\n",
              "      <td>internet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...</td>\n",
              "      <td>report</td>\n",
              "      <td>phone_issues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                  Sentence Utterance   Action        Object\n",
              "0   <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counte...  enquire       payment\n",
              "1               internet ยังความเร็วอยุ่เท่าไหร ครับ  enquire       package\n",
              "2   ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้...   report       suspend\n",
              "3   พี่ค่ะยังใช้ internet ไม่ได้เลยค่ะ เป็นเครื่อ...  enquire      internet\n",
              "4   ฮาโหล คะ พอดีว่าเมื่อวานเปิดซิมทรูมูฟ แต่มันโ...   report  phone_issues"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Show the top 5 rows\n",
        "display(data_df.head())\n",
        "# Summarize the data\n",
        "data_df.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGd8BNvMMc5y"
      },
      "source": [
        "## Data cleaning\n",
        "\n",
        "We call the DataFrame.describe() again.\n",
        "Notice that there are 33 unique labels/classes for object and 10 unique labels for action that the model will try to predict.\n",
        "But there are unwanted duplications e.g. Idd,idd,lotalty_card,Lotalty_card\n",
        "\n",
        "Also note that, there are 13389 unqiue sentence utterances from 16175 utterances. You have to clean that too!\n",
        "\n",
        "## #TODO 0.1:\n",
        "- You will have to remove unwanted label duplications as well as duplications in text inputs.\n",
        "- Also, you will have to trim out unwanted whitespaces from the text inputs.\n",
        "\n",
        "This shouldn't be too hard, as you have already seen it in the demo.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "V0bGLblVMc5z",
        "outputId": "1a65aff5-6196-4674-fb5d-36aa1afcfdba"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Sentence Utterance</th>\n",
              "      <th>Action</th>\n",
              "      <th>Object</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "      <td>16175</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13389</td>\n",
              "      <td>10</td>\n",
              "      <td>33</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>บริการอื่นๆ</td>\n",
              "      <td>enquire</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>97</td>\n",
              "      <td>10377</td>\n",
              "      <td>2525</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Sentence Utterance   Action   Object\n",
              "count               16175    16175    16175\n",
              "unique              13389       10       33\n",
              "top           บริการอื่นๆ  enquire  service\n",
              "freq                   97    10377     2525"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
              "       'service', 'nonTrueMove', 'balance', 'detail', 'bill', 'credit',\n",
              "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
              "       'information', 'lost_stolen', 'balance_minutes', 'idd',\n",
              "       'TrueMoney', 'garbage', 'Payment', 'IDD', 'ringtone', 'Idd',\n",
              "       'rate', 'loyalty_card', 'contact', 'officer', 'Balance', 'Service',\n",
              "       'Loyalty_card'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['enquire', 'report', 'cancel', 'Enquire', 'buy', 'activate',\n",
              "       'request', 'Report', 'garbage', 'change'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(data_df.describe())\n",
        "display(data_df.Object.unique())\n",
        "display(data_df.Action.unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "19onNNUZMc54"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>input</th>\n",
              "      <th>clean_label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>13367</td>\n",
              "      <td>13367</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>unique</th>\n",
              "      <td>13367</td>\n",
              "      <td>26</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>top</th>\n",
              "      <td>&lt;PHONE_NUMBER_REMOVED&gt; ผมไปจ่ายเงินที่ Counter...</td>\n",
              "      <td>service</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>freq</th>\n",
              "      <td>1</td>\n",
              "      <td>2108</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                    input clean_label\n",
              "count                                               13367       13367\n",
              "unique                                              13367          26\n",
              "top     <PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter...     service\n",
              "freq                                                    1        2108"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', 'internet', 'phone_issues',\n",
              "       'service', 'nontruemove', 'balance', 'detail', 'bill', 'credit',\n",
              "       'promotion', 'mobile_setting', 'iservice', 'roaming', 'truemoney',\n",
              "       'information', 'lost_stolen', 'balance_minutes', 'idd', 'garbage',\n",
              "       'ringtone', 'rate', 'loyalty_card', 'contact', 'officer'],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# TODO 1: Data Cleaning\n",
        "\n",
        "# Filter cols\n",
        "cols = [\"Sentence Utterance\", \"Object\"]\n",
        "data_df = data_df[cols]\n",
        "data_df.columns = ['input', 'raw_label']\n",
        "\n",
        "# Lowercase: label\n",
        "data_df['clean_label']=data_df['raw_label'].str.lower().copy()\n",
        "data_df.drop('raw_label', axis=1, inplace=True)\n",
        "\n",
        "# Trim white spaces: input\n",
        "data_df['input'] = data_df['input'].str.strip()\n",
        "\n",
        "# Remove duplicate: input\n",
        "data_df = data_df.drop_duplicates(subset=['input'], keep='first')\n",
        "\n",
        "# Display summary\n",
        "display(data_df.describe())\n",
        "display(data_df['clean_label'].unique())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIxnPRiAmrhN"
      },
      "source": [
        "Split data into train, valdation, and test sets (normally the ratio will be 80:10:10 , respectively). We recommend to use train_test_spilt from scikit-learn to split the data into train, validation, test set.\n",
        "\n",
        "In addition, it should split the data that distribution of the labels in train, validation, test set are similar. There is **stratify** option to handle this issue.\n",
        "\n",
        "https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html\n",
        "\n",
        "Make sure the same data splitting is used for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Create Mappings\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "{0: 'payment',\n",
              " 1: 'package',\n",
              " 2: 'suspend',\n",
              " 3: 'internet',\n",
              " 4: 'phone_issues',\n",
              " 5: 'service',\n",
              " 6: 'nontruemove',\n",
              " 7: 'balance',\n",
              " 8: 'detail',\n",
              " 9: 'bill',\n",
              " 10: 'credit',\n",
              " 11: 'promotion',\n",
              " 12: 'mobile_setting',\n",
              " 13: 'iservice',\n",
              " 14: 'roaming',\n",
              " 15: 'truemoney',\n",
              " 16: 'information',\n",
              " 17: 'lost_stolen',\n",
              " 18: 'balance_minutes',\n",
              " 19: 'idd',\n",
              " 20: 'garbage',\n",
              " 21: 'ringtone',\n",
              " 22: 'rate',\n",
              " 23: 'loyalty_card',\n",
              " 24: 'contact',\n",
              " 25: 'officer'}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/plain": [
              "{'payment': 0,\n",
              " 'package': 1,\n",
              " 'suspend': 2,\n",
              " 'internet': 3,\n",
              " 'phone_issues': 4,\n",
              " 'service': 5,\n",
              " 'nontruemove': 6,\n",
              " 'balance': 7,\n",
              " 'detail': 8,\n",
              " 'bill': 9,\n",
              " 'credit': 10,\n",
              " 'promotion': 11,\n",
              " 'mobile_setting': 12,\n",
              " 'iservice': 13,\n",
              " 'roaming': 14,\n",
              " 'truemoney': 15,\n",
              " 'information': 16,\n",
              " 'lost_stolen': 17,\n",
              " 'balance_minutes': 18,\n",
              " 'idd': 19,\n",
              " 'garbage': 20,\n",
              " 'ringtone': 21,\n",
              " 'rate': 22,\n",
              " 'loyalty_card': 23,\n",
              " 'contact': 24,\n",
              " 'officer': 25}"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before Mappings\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array(['payment', 'package', 'suspend', ..., 'balance', 'balance',\n",
              "       'package'], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "After Mappings\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "array([0, 1, 2, ..., 7, 7, 1], dtype=object)"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Before\n",
            "[['<PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท'\n",
            "  0]\n",
            " ['internet ยังความเร็วอยุ่เท่าไหร ครับ' 1]\n",
            " ['ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ' 2]\n",
            " ...\n",
            " ['ยอดเงินเหลือเท่าไหร่ค่ะ' 7]\n",
            " ['ยอดเงินในระบบ' 7]\n",
            " ['สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ' 1]]\n",
            "After\n",
            "[['<PHONE_NUMBER_REMOVED> ผมไปจ่ายเงินที่ Counter Services เค้าเช็ต 3276.25 บาท เมื่อวานที่ผมเช็คที่ศูนย์บอกมียอด 3057.79 บาท'\n",
            "  0]\n",
            " ['internet ยังความเร็วอยุ่เท่าไหร ครับ' 1]\n",
            " ['ตะกี้ไปชำระค่าบริการไปแล้ว แต่ยังใช้งานไม่ได้ ค่ะ' 2]\n",
            " ...\n",
            " ['ยอดเงินเหลือเท่าไหร่ค่ะ' 7]\n",
            " ['ยอดเงินในระบบ' 7]\n",
            " ['สอบถามโปรโมชั่นปัจจุบันที่ใช้อยู่ค่ะ' 1]]\n"
          ]
        }
      ],
      "source": [
        "# Mapping\n",
        "data = data_df.to_numpy()\n",
        "\n",
        "unique_label = data_df.clean_label.unique()\n",
        "\n",
        "label_2_num_map = dict(zip(unique_label, range(len(unique_label))))\n",
        "num_2_label_map = dict(zip(range(len(unique_label)), unique_label))\n",
        "\n",
        "print(\"Create Mappings\")\n",
        "display(num_2_label_map)\n",
        "display(label_2_num_map)\n",
        "\n",
        "print(\"Before Mappings\")\n",
        "display(data[:, 1])\n",
        "data[:,1] = np.vectorize(label_2_num_map.get)(data[:,1]) # Mapping...\n",
        "print(\"After Mappings\")\n",
        "display(data[:, 1])\n",
        "\n",
        "# Trim\n",
        "def strip_str(string):\n",
        "    return string.strip()\n",
        "print(\"Before\")\n",
        "print(data)\n",
        "data[:,0] = np.vectorize(strip_str)(data[:,0]) # Trimming...\n",
        "print(\"After\")\n",
        "print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train size: 10690\n",
            "Validation size: 1336\n",
            "Test size: 1337\n"
          ]
        }
      ],
      "source": [
        "# TODO: Split data\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "SEED = 42\n",
        "\n",
        "def split_data(data_df, random_state=SEED):\n",
        "    \"\"\"split_data splits the data into train:validation:test=8:1:1 sets.\"\"\"\n",
        "\n",
        "    def _filter_data(data_df):\n",
        "        X = data_df[\"input\"]\n",
        "        y = data_df[\"clean_label\"]\n",
        "        # Drop classes with fewer than 10(8:1:1) instances\n",
        "        class_counts = y.value_counts()\n",
        "        valid_classes = class_counts[class_counts >= 10].index\n",
        "        filtered_data = data_df[data_df[\"clean_label\"].isin(valid_classes)]\n",
        "        # Update X and y after filtering\n",
        "        X = filtered_data[\"input\"]\n",
        "        y = filtered_data[\"clean_label\"]\n",
        "        return X, y.astype(int)\n",
        "\n",
        "    X, y = _filter_data(data_df)\n",
        "\n",
        "    # First split: Train (80%) and Temp (20%)\n",
        "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
        "        X, y, test_size=0.20, stratify=y, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Second split: Validation (10%) and Test (10%)\n",
        "    X_val, X_test, y_val, y_test = train_test_split(\n",
        "        X_temp, y_temp, test_size=0.50, stratify=y_temp, random_state=random_state\n",
        "    )\n",
        "\n",
        "    # Display dataset sizes\n",
        "    print(f\"Train size: {len(X_train)}\")\n",
        "    print(f\"Validation size: {len(X_val)}\")\n",
        "    print(f\"Test size: {len(X_test)}\")\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test\n",
        "\n",
        "\n",
        "# Split\n",
        "df = pd.DataFrame(data, columns=['input', 'clean_label'])\n",
        "X_train, X_val, X_test, y_train, y_val, y_test = split_data(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDHfX377rnp_"
      },
      "source": [
        "# Model 3 WangchanBERTa\n",
        "\n",
        "We ask you to train a WangchanBERTa-based model.\n",
        "\n",
        "We recommend you use the thaixtransformers fork (which we used in the PoS homework).\n",
        "https://github.com/PyThaiNLP/thaixtransformers\n",
        "\n",
        "The structure of the code will be very similar to the PoS homework. You will also find the huggingface [tutorial](https://huggingface.co/docs/transformers/en/tasks/sequence_classification) useful. Or you can also add a softmax layer by yourself just like in the previous homework.\n",
        "\n",
        "Which WangchanBERTa model will you use? Why? (Don't forget to clean your text accordingly).\n",
        "\n",
        "**Ans:** `airesearch/wangchanberta-base-att-spm-uncased` because\n",
        "- specifically trained for Thai text.\n",
        "- SentencePiece tokenization, which is ideal for Thai, unlike space-based tokenization.\n",
        "- It has state-of-the-art performance for Thai text classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI8SvILyub0m"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at airesearch/wangchanberta-base-att-spm-uncased and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m The `run_name` is currently set to the same value as `TrainingArguments.output_dir`. If this was not intended, please specify a different run name by setting the `TrainingArguments.run_name` parameter.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpupipat-sk\u001b[0m (\u001b[33mpupipatsk\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
            "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
            "To disable this warning, you can either:\n",
            "\t- Avoid using `tokenizers` before the fork if possible\n",
            "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.19.2"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/pupipatsingkhorn/Developer/repositories/NLP/HW-06/wandb/run-20250213_210610-si1gdil7</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/pupipatsk/huggingface/runs/si1gdil7' target=\"_blank\">./results</a></strong> to <a href='https://wandb.ai/pupipatsk/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/pupipatsk/huggingface' target=\"_blank\">https://wandb.ai/pupipatsk/huggingface</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/pupipatsk/huggingface/runs/si1gdil7' target=\"_blank\">https://wandb.ai/pupipatsk/huggingface/runs/si1gdil7</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2007' max='2007' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2007/2007 37:26, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>2.656900</td>\n",
              "      <td>1.528242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.627300</td>\n",
              "      <td>0.801987</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.659800</td>\n",
              "      <td>0.763643</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='168' max='84' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [84/84 00:34]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "KeyError",
          "evalue": "'eval_accuracy'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[11], line 61\u001b[0m\n\u001b[1;32m     58\u001b[0m val_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(val_dataset)\n\u001b[1;32m     59\u001b[0m test_results \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mevaluate(test_dataset)\n\u001b[0;32m---> 61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mval_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_results[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124meval_accuracy\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "\u001b[0;31mKeyError\u001b[0m: 'eval_accuracy'"
          ]
        }
      ],
      "source": [
        "# TODO: Implement WangchanBERTa\n",
        "# TODO: New build\n",
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "\n",
        "# Define the WangchanBERTa model\n",
        "MODEL_NAME = \"airesearch/wangchanberta-base-att-spm-uncased\"\n",
        "\n",
        "# Load tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME)\n",
        "\n",
        "# Define a dataset class\n",
        "class TextDataset(Dataset):\n",
        "    def __init__(self, texts, labels, tokenizer, max_length=128):\n",
        "        self.encodings = tokenizer(texts.tolist(), truncation=True, padding=True, max_length=max_length)\n",
        "        self.labels = labels.tolist()\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item[\"labels\"] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "# Convert data into dataset format\n",
        "train_dataset = TextDataset(X_train, y_train, tokenizer)\n",
        "val_dataset = TextDataset(X_val, y_val, tokenizer)\n",
        "test_dataset = TextDataset(X_test, y_test, tokenizer)\n",
        "\n",
        "# Load pre-trained WangchanBERTa model for classification\n",
        "model = AutoModelForSequenceClassification.from_pretrained(MODEL_NAME, num_labels=len(set(y_train)))\n",
        "\n",
        "# Define training arguments\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"./results\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    num_train_epochs=3,\n",
        "    per_device_train_batch_size=16,\n",
        "    per_device_eval_batch_size=16,\n",
        "    logging_dir=\"./logs\",\n",
        "    logging_steps=500,\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True\n",
        ")\n",
        "\n",
        "# Define trainer\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset\n",
        ")\n",
        "\n",
        "# Train model\n",
        "trainer.train()\n",
        "\n",
        "# Evaluate model on validation and test sets\n",
        "val_results = trainer.evaluate(val_dataset)\n",
        "test_results = trainer.evaluate(test_dataset)\n",
        "\n",
        "print(f\"Validation Accuracy: {val_results['eval_accuracy']:.4f}\")\n",
        "print(f\"Test Accuracy: {test_results['eval_accuracy']:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr9_0DnMBcFZ"
      },
      "source": [
        "# Comparison\n",
        "\n",
        "After you have completed the 3 models, compare the accuracy, ease of implementation, and inference speed (from cleaning, tokenization, till model compute) between the three models in mycourseville."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "datascience",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
